{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n1', 0), ('n2', 0), ('n3', 0), ('n4', 0), ('n5', 0), ('n6', 0), ('n7', 1), ('n8', 1), ('n9', 1), ('n10', 1), ('n11', 1), ('n12', 1), ('n13', 2), ('n14', 2), ('n15', 2), ('n16', 2), ('n17', 2), ('n18', 2)]\n",
      "[('n1', 'n2'), ('n1', 'n3'), ('n1', 'n5'), ('n2', 'n4'), ('n3', 'n6'), ('n3', 'n9'), ('n4', 'n5'), ('n4', 'n6'), ('n4', 'n8'), ('n5', 'n14'), ('n7', 'n8'), ('n7', 'n9'), ('n7', 'n11'), ('n8', 'n10'), ('n8', 'n11'), ('n8', 'n12'), ('n9', 'n10'), ('n9', 'n14'), ('n10', 'n12'), ('n11', 'n18'), ('n13', 'n15'), ('n13', 'n16'), ('n13', 'n18'), ('n14', 'n16'), ('n14', 'n18'), ('n15', 'n16'), ('n15', 'n18'), ('n17', 'n18')]\n"
     ]
    }
   ],
   "source": [
    "# (node, label)集\n",
    "N = [(\"n{}\".format(i), 0) for i in range(1, 7)] + \\\n",
    "    [(\"n{}\".format(i), 1) for i in range(7, 13)] + \\\n",
    "    [(\"n{}\".format(i), 2) for i in range(13, 19)]\n",
    "# 边集\n",
    "E = [(\"n1\", \"n2\"), (\"n1\", \"n3\"), (\"n1\", \"n5\"),\n",
    "     (\"n2\", \"n4\"),\n",
    "     (\"n3\", \"n6\"), (\"n3\", \"n9\"),\n",
    "     (\"n4\", \"n5\"), (\"n4\", \"n6\"), (\"n4\", \"n8\"),\n",
    "     (\"n5\", \"n14\"),\n",
    "     (\"n7\", \"n8\"), (\"n7\", \"n9\"), (\"n7\", \"n11\"),\n",
    "     (\"n8\", \"n10\"), (\"n8\", \"n11\"), (\"n8\", \"n12\"),\n",
    "     (\"n9\", \"n10\"), (\"n9\", \"n14\"),\n",
    "     (\"n10\", \"n12\"),\n",
    "     (\"n11\", \"n18\"),\n",
    "     (\"n13\", \"n15\"), (\"n13\", \"n16\"), (\"n13\", \"n18\"),\n",
    "     (\"n14\", \"n16\"), (\"n14\", \"n18\"),\n",
    "     (\"n15\", \"n16\"), (\"n15\", \"n18\"),\n",
    "     (\"n17\", \"n18\")]\n",
    "\n",
    "print(N)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G=nx.Graph()\n",
    "nodes = list(map(lambda x: x[0], N))\n",
    "G.add_nodes_from(list(map(lambda x:x[0],N)))\n",
    "G.add_edges_from(E)\n",
    "#设置属性\n",
    "ncolor = ['r'] * 6 + ['b'] * 6 + ['g'] * 6\n",
    "nsize = [700] * 6 + [700] * 6 + [700] * 6\n",
    "# 显示Graph\n",
    "plt.figure(1)\n",
    "nx.draw(G, with_labels=True, font_weight='bold',\n",
    "        node_color=ncolor, node_size=nsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xi(nn.Module):\n",
    "    \"\"\"\n",
    "    实现Xi函数，输入一个batch的相邻节点特征向量对ln，返回的是s*s的A矩阵\n",
    "    \"\"\"\n",
    "    def __init__(self,ln,s) -> None:\n",
    "        super().__init__()\n",
    "        self.ln=ln\n",
    "        self.s = s\n",
    "        # linear layer \n",
    "        self.linear = nn.Linear(2*self.ln,s*s,bias=True)\n",
    "        # activation layer\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self,X:t.Tensor):\n",
    "        \"\"\"\n",
    "        X: (N,2*ln)输入节点特征以及邻居节点特征concat起来\n",
    "        return : (N,S,S)，输出用于线性变换的参数矩阵\n",
    "        \"\"\"\n",
    "        bs= X.size()[0]\n",
    "        out = self.linear(X)\n",
    "        out = self.tanh(out)\n",
    "        out = out.view(bs,self.s,self.s)\n",
    "        return out\n",
    "    \n",
    "# function Rou\n",
    "class Rou(nn.Module):\n",
    "    def __init__(self,ln,s) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(ln,s),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,X:t.Tensor):\n",
    "        out = self.linear(X)\n",
    "        return out\n",
    "\n",
    "class Hw(nn.Module):\n",
    "    def __init__(self,ln,s,mu=0.9) -> None:\n",
    "        super().__init__()\n",
    "        self.ln=ln\n",
    "        self.s=s\n",
    "        self.mu =mu\n",
    "        # init network layers\n",
    "        self.Xi = Xi(self.ln,self.s)\n",
    "        self.Rou = Rou(self.ln,self.s)\n",
    "\n",
    "    def forward(self,X,H,dg_list):\n",
    "        \"\"\"\n",
    "        X (N,2*ln)一个节点特征向量和该节点的某一个邻接向量concatenate得到的向量\n",
    "        H (N,s)对应中心节点的状态向量\n",
    "        dg_list : (N,) 对应中心节点的度的向量\n",
    "        return :(N,s)\n",
    "        \"\"\"\n",
    "        if type(dg_list)==list:\n",
    "            dg_list = t.tensor(dg_list)\n",
    "        elif isinstance(dg_list,t.Tensor):\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"==> dg_list should be list or tensor, not {}\".format(type(dg_list)))\n",
    "        A= (self.Xi(X)*self.mu/self.s)/dg_list.view(-1,1,1)\n",
    "        b=self.Rou(t.chunk(X,chunks=2,dim=1)[0])\n",
    "        # (N, s, s) * (N, s) + (N, s)\n",
    "        out = t.squeeze(t.matmul(A, t.unsqueeze(H, 2)), -1) + b\n",
    "        return out    # (N, s)\n",
    "\n",
    "class AggrSum(nn.Module):\n",
    "    \"\"\"\n",
    "    信息聚合\n",
    "    \"\"\"\n",
    "    def __init__(self,node_num:int) -> None:\n",
    "        super().__init__()\n",
    "        self.V= node_num\n",
    "\n",
    "    def forward(self, H:t.Tensor, X_node: t.Tensor)->t.Tensor:\n",
    "        # H: (N,s)->(V,s)\n",
    "        # X_node:(N,)\n",
    "        mask=t.stack([X_node]*self.V,0)\n",
    "        mask=mask.float()-t.unsqueeze(t.range(0,self.V-1).float(),1)\n",
    "        mask = (mask==0).float()\n",
    "        # (V,N)*(N,s)->(V,s)\n",
    "        return t.mm(mask,H)\n",
    "\n",
    "class OriLinearGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The graph neural network model\n",
    "    \"\"\"\n",
    "    def __init__(self,node_num,feat_dim,stat_dim,T) -> None:\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        初始化模型函数。\n",
    "        \n",
    "        :param node_num: 节点数量\n",
    "        :param feat_dim: 节点特征维度\n",
    "        :param stat_dim: 节点状态维度\n",
    "        :param T       : GNN更新轮数\n",
    "        \"\"\"\n",
    "        self.node_num=node_num\n",
    "        self.feat_dim= feat_dim\n",
    "        self.stat_dim=stat_dim\n",
    "        self.T=T\n",
    "        # 初始化节点的嵌入向量，也就是hv，(V,ln)\n",
    "        self.node_features=nn.parameter.Parameter(\n",
    "            data=t.randn((self.node_num,self.feat_dim),dtype=t.float32),\n",
    "            requires_grad=True)\n",
    "        # 输出层g\n",
    "        self.linear=nn.Linear(feat_dim+stat_dim,3)\n",
    "        self.softmax = nn.Softmax(0)\n",
    "        # Fw\n",
    "        self.Hw=Hw(feat_dim,stat_dim)\n",
    "        # H的分组求和\n",
    "        self.Aggr = AggrSum(node_num)\n",
    "    \n",
    "    def forward(self,X_Node,X_Neis,dg_list):\n",
    "        \"\"\"前向计算函数。值得注意的是，这里输入的X_Node和N_Neis的第一个维度`N`表示边的个数。\n",
    "        比如：\n",
    "            X_Node: [0, 0, 0, 1, 1, ..., 18, 18]\n",
    "            X_Neis: [1, 2, 4, 1, 4, ..., 11, 13]\n",
    "        :param X_Node: 节点索引\n",
    "        :param X_Neis: X_node对应节点邻居的索引\n",
    "        :param dg_list: 节点的度列表\n",
    "        \"\"\"\n",
    "        node_embeds=self.node_features[X_Node]\n",
    "        neis_embeds=self.node_features[X_Neis]\n",
    "        X=t.cat((node_embeds,neis_embeds),1)\n",
    "        # 初始化节点的状态向量\n",
    "        node_states=t.zeros((self.node_num,self.stat_dim),dtype=t.float32)\n",
    "        # 循环t次\n",
    "        for _ in range(self.T):\n",
    "            # (V,s)->(N,s)\n",
    "            H=t.index_select(node_states,0,X_Node)\n",
    "            #(N,s)->(N,s)\n",
    "            H=self.Hw(X,H,dg_list)\n",
    "            #(N,s)->(V,s)\n",
    "            node_states=self.Aggr(H,X_Node)\n",
    "        out = self.linear(t.cat((self.node_features.data,node_states),1))\n",
    "        out =self.softmax(out)\n",
    "        return out # (V,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalclulateAccuracy(output,label):\n",
    "    # output: (N,C)\n",
    "    # label :(N)\n",
    "    output=np.argmax(output,axis=1)\n",
    "    res = output-label\n",
    "    return list(res).count(0)/len(res)\n",
    "\n",
    "# training \n",
    "def train(node_list,edge_list,label_list,T,ndict_path=\"./data/node_dict.json\"):\n",
    "    if os.path.exists(ndict_path):\n",
    "        with open(ndict_path) as fp:\n",
    "            node_dict=json.load(fp)\n",
    "    else:\n",
    "        node_dict=dict([(node,ind) for ind,node in enumerate(node_list)])\n",
    "        node_dict={\"stoi\":node_dict,\n",
    "        \"itos\":node_list}\n",
    "        with open(ndict_path,\"w\") as fp:\n",
    "            json.dump(node_dict,fp)\n",
    "    \n",
    "    # 现在需要生成两个向量\n",
    "    # 第一个向量类似于\n",
    "    #   [0, 0, 0, 1, 1, ..., 18, 18]\n",
    "    # 其中的值表示节点的索引，连续相同索引的个数为该节点的度\n",
    "    # 第二个向量类似于\n",
    "    #   [1, 2, 4, 1, 4, ..., 11, 13]\n",
    "    # 与第一个向量一一对应，表示第一个向量节点的邻居节点\n",
    "\n",
    "    # 得到节点的度 degree\n",
    "    Degree=dict()\n",
    "    for n1,n2 in edge_list:\n",
    "        if n1 in Degree:\n",
    "            Degree[n1].add(n2)\n",
    "        else:\n",
    "            Degree[n1]={n2}\n",
    "        if n2 in Degree:\n",
    "            Degree[n2].add(n1)\n",
    "        else:\n",
    "            Degree[n2]={n1}\n",
    "    \n",
    "    # 生成两个向量\n",
    "    node_inds=[]\n",
    "    node_neis=[]\n",
    "    for n in node_list:\n",
    "        node_inds+=[node_dict[\"stoi\"][n]]*len(Degree[n])\n",
    "        node_neis+=list(map(lambda x:node_dict[\"stoi\"][x],list(Degree[n])))\n",
    "\n",
    "    # 生成度向量\n",
    "    dg_list = list(map(lambda x:len(Degree[node_dict[\"itos\"][x]]),node_inds))\n",
    "\n",
    "    # 训练集和测试集\n",
    "    train_node_list = [0, 1, 2, 6, 7, 8, 12, 13, 14]\n",
    "    train_node_label = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "    test_node_list = [3, 4, 5, 9, 10, 11, 15, 16, 17]\n",
    "    test_node_label = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "\n",
    "    # 开始训练\n",
    "    model = OriLinearGNN(node_num=len(node_list),feat_dim=2,stat_dim=2,T=T)\n",
    "    optimizer=t.optim.Adam(model.parameters(),lr=0.01,weight_decay=0.01)\n",
    "    loss_func  = nn.CrossEntropyLoss(size_average=True)\n",
    "\n",
    "    min_loss=float(\"inf\")\n",
    "    train_loss_list = []\n",
    "    train_acc_list=[]\n",
    "    test_acc_list=[]\n",
    "    node_inds_tensor = t.tensor(node_inds,dtype=t.long)\n",
    "    node_neis_tensor=t.tensor(node_neis,dtype=t.long)\n",
    "    train_label=t.tensor(train_node_label,dtype=t.long)\n",
    "\n",
    "    for ep in range(500):\n",
    "        # 运行模型得到结果\n",
    "        with t.autograd.set_detect_anomaly(True):\n",
    "            res = model(node_inds_tensor, node_neis_tensor, dg_list)  # (V, 3)\n",
    "            train_res = t.index_select(\n",
    "                res, 0, t.Tensor(train_node_list).long())\n",
    "            test_res = t.index_select(\n",
    "                res, 0, t.Tensor(test_node_list).long())\n",
    "            loss = loss_func(input=train_res,\n",
    "                             target=train_label)\n",
    "            loss_val = loss.item()\n",
    "            train_acc = CalclulateAccuracy(\n",
    "                train_res.cpu().detach().numpy(), np.array(train_node_label))\n",
    "            test_acc = CalclulateAccuracy(\n",
    "                test_res.cpu().detach().numpy(), np.array(test_node_label))\n",
    "            # 更新梯度\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        # 保存loss和acc\n",
    "        train_loss_list.append(loss_val)\n",
    "        test_acc_list.append(test_acc)\n",
    "        train_acc_list.append(train_acc)\n",
    "\n",
    "        if loss_val < min_loss:\n",
    "            min_loss = loss_val\n",
    "        print(\"==> [Epoch {}] : loss {:.4f}, min_loss {:.4f}, train_acc {:.3f}, test_acc {:.3f}\".format(\n",
    "            ep, loss_val, min_loss, train_acc, test_acc))\n",
    "    return train_loss_list, train_acc_list, test_acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\develop\\anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\22502\\AppData\\Local\\Temp/ipykernel_1952/610473214.py:79: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  mask=mask.float()-t.unsqueeze(t.range(0,self.V-1).float(),1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> [Epoch 0] : loss 1.1045, min_loss 1.1045, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 1] : loss 1.1040, min_loss 1.1040, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 2] : loss 1.1035, min_loss 1.1035, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 3] : loss 1.1030, min_loss 1.1030, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 4] : loss 1.1026, min_loss 1.1026, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 5] : loss 1.1021, min_loss 1.1021, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 6] : loss 1.1017, min_loss 1.1017, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 7] : loss 1.1013, min_loss 1.1013, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 8] : loss 1.1009, min_loss 1.1009, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 9] : loss 1.1005, min_loss 1.1005, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 10] : loss 1.1001, min_loss 1.1001, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 11] : loss 1.0997, min_loss 1.0997, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 12] : loss 1.0992, min_loss 1.0992, train_acc 0.444, test_acc 0.444\n",
      "==> [Epoch 13] : loss 1.0988, min_loss 1.0988, train_acc 0.333, test_acc 0.444\n",
      "==> [Epoch 14] : loss 1.0984, min_loss 1.0984, train_acc 0.333, test_acc 0.444\n",
      "==> [Epoch 15] : loss 1.0979, min_loss 1.0979, train_acc 0.333, test_acc 0.444\n",
      "==> [Epoch 16] : loss 1.0975, min_loss 1.0975, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 17] : loss 1.0969, min_loss 1.0969, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 18] : loss 1.0964, min_loss 1.0964, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 19] : loss 1.0958, min_loss 1.0958, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 20] : loss 1.0952, min_loss 1.0952, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 21] : loss 1.0945, min_loss 1.0945, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 22] : loss 1.0938, min_loss 1.0938, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 23] : loss 1.0930, min_loss 1.0930, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 24] : loss 1.0922, min_loss 1.0922, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 25] : loss 1.0912, min_loss 1.0912, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 26] : loss 1.0902, min_loss 1.0902, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 27] : loss 1.0891, min_loss 1.0891, train_acc 0.444, test_acc 0.444\n",
      "==> [Epoch 28] : loss 1.0879, min_loss 1.0879, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 29] : loss 1.0865, min_loss 1.0865, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 30] : loss 1.0850, min_loss 1.0850, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 31] : loss 1.0834, min_loss 1.0834, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 32] : loss 1.0815, min_loss 1.0815, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 33] : loss 1.0794, min_loss 1.0794, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 34] : loss 1.0771, min_loss 1.0771, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 35] : loss 1.0745, min_loss 1.0745, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 36] : loss 1.0715, min_loss 1.0715, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 37] : loss 1.0682, min_loss 1.0682, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 38] : loss 1.0645, min_loss 1.0645, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 39] : loss 1.0605, min_loss 1.0605, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 40] : loss 1.0563, min_loss 1.0563, train_acc 0.556, test_acc 0.333\n",
      "==> [Epoch 41] : loss 1.0520, min_loss 1.0520, train_acc 0.556, test_acc 0.333\n",
      "==> [Epoch 42] : loss 1.0477, min_loss 1.0477, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 43] : loss 1.0437, min_loss 1.0437, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 44] : loss 1.0401, min_loss 1.0401, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 45] : loss 1.0371, min_loss 1.0371, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 46] : loss 1.0347, min_loss 1.0347, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 47] : loss 1.0329, min_loss 1.0329, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 48] : loss 1.0316, min_loss 1.0316, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 49] : loss 1.0307, min_loss 1.0307, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 50] : loss 1.0300, min_loss 1.0300, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 51] : loss 1.0295, min_loss 1.0295, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 52] : loss 1.0291, min_loss 1.0291, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 53] : loss 1.0288, min_loss 1.0288, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 54] : loss 1.0285, min_loss 1.0285, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 55] : loss 1.0283, min_loss 1.0283, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 56] : loss 1.0280, min_loss 1.0280, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 57] : loss 1.0279, min_loss 1.0279, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 58] : loss 1.0277, min_loss 1.0277, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 59] : loss 1.0275, min_loss 1.0275, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 60] : loss 1.0274, min_loss 1.0274, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 61] : loss 1.0272, min_loss 1.0272, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 62] : loss 1.0271, min_loss 1.0271, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 63] : loss 1.0269, min_loss 1.0269, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 64] : loss 1.0268, min_loss 1.0268, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 65] : loss 1.0267, min_loss 1.0267, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 66] : loss 1.0265, min_loss 1.0265, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 67] : loss 1.0264, min_loss 1.0264, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 68] : loss 1.0263, min_loss 1.0263, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 69] : loss 1.0261, min_loss 1.0261, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 70] : loss 1.0260, min_loss 1.0260, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 71] : loss 1.0258, min_loss 1.0258, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 72] : loss 1.0256, min_loss 1.0256, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 73] : loss 1.0254, min_loss 1.0254, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 74] : loss 1.0252, min_loss 1.0252, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 75] : loss 1.0250, min_loss 1.0250, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 76] : loss 1.0247, min_loss 1.0247, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 77] : loss 1.0244, min_loss 1.0244, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 78] : loss 1.0241, min_loss 1.0241, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 79] : loss 1.0237, min_loss 1.0237, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 80] : loss 1.0234, min_loss 1.0234, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 81] : loss 1.0230, min_loss 1.0230, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 82] : loss 1.0226, min_loss 1.0226, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 83] : loss 1.0223, min_loss 1.0223, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 84] : loss 1.0220, min_loss 1.0220, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 85] : loss 1.0217, min_loss 1.0217, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 86] : loss 1.0214, min_loss 1.0214, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 87] : loss 1.0211, min_loss 1.0211, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 88] : loss 1.0209, min_loss 1.0209, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 89] : loss 1.0206, min_loss 1.0206, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 90] : loss 1.0203, min_loss 1.0203, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 91] : loss 1.0201, min_loss 1.0201, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 92] : loss 1.0198, min_loss 1.0198, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 93] : loss 1.0196, min_loss 1.0196, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 94] : loss 1.0194, min_loss 1.0194, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 95] : loss 1.0191, min_loss 1.0191, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 96] : loss 1.0189, min_loss 1.0189, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 97] : loss 1.0186, min_loss 1.0186, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 98] : loss 1.0184, min_loss 1.0184, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 99] : loss 1.0181, min_loss 1.0181, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 100] : loss 1.0178, min_loss 1.0178, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 101] : loss 1.0174, min_loss 1.0174, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 102] : loss 1.0170, min_loss 1.0170, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 103] : loss 1.0165, min_loss 1.0165, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 104] : loss 1.0159, min_loss 1.0159, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 105] : loss 1.0153, min_loss 1.0153, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 106] : loss 1.0147, min_loss 1.0147, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 107] : loss 1.0139, min_loss 1.0139, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 108] : loss 1.0131, min_loss 1.0131, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 109] : loss 1.0122, min_loss 1.0122, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 110] : loss 1.0111, min_loss 1.0111, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 111] : loss 1.0099, min_loss 1.0099, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 112] : loss 1.0086, min_loss 1.0086, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 113] : loss 1.0070, min_loss 1.0070, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 114] : loss 1.0052, min_loss 1.0052, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 115] : loss 1.0031, min_loss 1.0031, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 116] : loss 1.0008, min_loss 1.0008, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 117] : loss 0.9981, min_loss 0.9981, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 118] : loss 0.9952, min_loss 0.9952, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 119] : loss 0.9920, min_loss 0.9920, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 120] : loss 0.9887, min_loss 0.9887, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 121] : loss 0.9854, min_loss 0.9854, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 122] : loss 0.9823, min_loss 0.9823, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 123] : loss 0.9794, min_loss 0.9794, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 124] : loss 0.9770, min_loss 0.9770, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 125] : loss 0.9750, min_loss 0.9750, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 126] : loss 0.9735, min_loss 0.9735, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 127] : loss 0.9724, min_loss 0.9724, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 128] : loss 0.9715, min_loss 0.9715, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 129] : loss 0.9709, min_loss 0.9709, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 130] : loss 0.9705, min_loss 0.9705, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 131] : loss 0.9701, min_loss 0.9701, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 132] : loss 0.9699, min_loss 0.9699, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 133] : loss 0.9697, min_loss 0.9697, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 134] : loss 0.9695, min_loss 0.9695, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 135] : loss 0.9694, min_loss 0.9694, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 136] : loss 0.9693, min_loss 0.9693, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 137] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 138] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 139] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 140] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 141] : loss 0.9693, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 142] : loss 0.9693, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 143] : loss 0.9694, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 144] : loss 0.9695, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 145] : loss 0.9697, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 146] : loss 0.9698, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 147] : loss 0.9700, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 148] : loss 0.9701, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 149] : loss 0.9702, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 150] : loss 0.9702, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 151] : loss 0.9702, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 152] : loss 0.9701, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 153] : loss 0.9699, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 154] : loss 0.9697, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 155] : loss 0.9694, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 156] : loss 0.9690, min_loss 0.9690, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 157] : loss 0.9686, min_loss 0.9686, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 158] : loss 0.9681, min_loss 0.9681, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 159] : loss 0.9676, min_loss 0.9676, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 160] : loss 0.9671, min_loss 0.9671, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 161] : loss 0.9666, min_loss 0.9666, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 162] : loss 0.9661, min_loss 0.9661, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 163] : loss 0.9655, min_loss 0.9655, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 164] : loss 0.9649, min_loss 0.9649, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 165] : loss 0.9643, min_loss 0.9643, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 166] : loss 0.9637, min_loss 0.9637, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 167] : loss 0.9631, min_loss 0.9631, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 168] : loss 0.9625, min_loss 0.9625, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 169] : loss 0.9618, min_loss 0.9618, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 170] : loss 0.9610, min_loss 0.9610, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 171] : loss 0.9602, min_loss 0.9602, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 172] : loss 0.9594, min_loss 0.9594, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 173] : loss 0.9584, min_loss 0.9584, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 174] : loss 0.9574, min_loss 0.9574, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 175] : loss 0.9562, min_loss 0.9562, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 176] : loss 0.9548, min_loss 0.9548, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 177] : loss 0.9532, min_loss 0.9532, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 178] : loss 0.9514, min_loss 0.9514, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 179] : loss 0.9493, min_loss 0.9493, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 180] : loss 0.9470, min_loss 0.9470, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 181] : loss 0.9444, min_loss 0.9444, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 182] : loss 0.9416, min_loss 0.9416, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 183] : loss 0.9387, min_loss 0.9387, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 184] : loss 0.9357, min_loss 0.9357, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 185] : loss 0.9327, min_loss 0.9327, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 186] : loss 0.9298, min_loss 0.9298, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 187] : loss 0.9272, min_loss 0.9272, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 188] : loss 0.9247, min_loss 0.9247, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 189] : loss 0.9225, min_loss 0.9225, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 190] : loss 0.9206, min_loss 0.9206, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 191] : loss 0.9190, min_loss 0.9190, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 192] : loss 0.9176, min_loss 0.9176, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 193] : loss 0.9165, min_loss 0.9165, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 194] : loss 0.9156, min_loss 0.9156, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 195] : loss 0.9149, min_loss 0.9149, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 196] : loss 0.9144, min_loss 0.9144, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 197] : loss 0.9140, min_loss 0.9140, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 198] : loss 0.9137, min_loss 0.9137, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 199] : loss 0.9135, min_loss 0.9135, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 200] : loss 0.9134, min_loss 0.9134, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 201] : loss 0.9133, min_loss 0.9133, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 202] : loss 0.9133, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 203] : loss 0.9134, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 204] : loss 0.9135, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 205] : loss 0.9136, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 206] : loss 0.9138, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 207] : loss 0.9140, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 208] : loss 0.9142, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 209] : loss 0.9143, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 210] : loss 0.9144, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 211] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 212] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 213] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 214] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 215] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 216] : loss 0.9145, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 217] : loss 0.9144, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 218] : loss 0.9142, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 219] : loss 0.9140, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 220] : loss 0.9138, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 221] : loss 0.9136, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 222] : loss 0.9134, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 223] : loss 0.9131, min_loss 0.9131, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 224] : loss 0.9128, min_loss 0.9128, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 225] : loss 0.9126, min_loss 0.9126, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 226] : loss 0.9123, min_loss 0.9123, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 227] : loss 0.9120, min_loss 0.9120, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 228] : loss 0.9117, min_loss 0.9117, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 229] : loss 0.9115, min_loss 0.9115, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 230] : loss 0.9112, min_loss 0.9112, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 231] : loss 0.9110, min_loss 0.9110, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 232] : loss 0.9107, min_loss 0.9107, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 233] : loss 0.9105, min_loss 0.9105, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 234] : loss 0.9104, min_loss 0.9104, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 235] : loss 0.9102, min_loss 0.9102, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 236] : loss 0.9101, min_loss 0.9101, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 237] : loss 0.9100, min_loss 0.9100, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 238] : loss 0.9099, min_loss 0.9099, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 239] : loss 0.9098, min_loss 0.9098, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 240] : loss 0.9098, min_loss 0.9098, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 241] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 242] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 243] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 244] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 245] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 246] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 247] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 248] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 249] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 250] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 251] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 252] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 253] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 254] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 255] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 256] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 257] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 258] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 259] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 260] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 261] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 262] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 263] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 264] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 265] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 266] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 267] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 268] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 269] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 270] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 271] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 272] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 273] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 274] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 275] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 276] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 277] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 278] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 279] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 280] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 281] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 282] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 283] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 284] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 285] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 286] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 287] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 288] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 289] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 290] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 291] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 292] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 293] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 294] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 295] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 296] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 297] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 298] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 299] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 300] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 301] : loss 0.9093, min_loss 0.9093, train_acc 1.000, test_acc 0.444\n",
      "==> [Epoch 302] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 303] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 304] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 305] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 306] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 307] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 308] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 309] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 310] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 311] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 312] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 313] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 314] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 315] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 316] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 317] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 318] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 319] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 320] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 321] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 322] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 323] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 324] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 325] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 326] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 327] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 328] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 329] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 330] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 331] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 332] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 333] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 334] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 335] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 336] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 337] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 338] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 339] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 340] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 341] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 342] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 343] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 344] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 345] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 346] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 347] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 348] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 349] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 350] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 351] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 352] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 353] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 354] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 355] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 356] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 357] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 358] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 359] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 360] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 361] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 362] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 363] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 364] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 365] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 366] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 367] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 368] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 369] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 370] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 371] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 372] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 373] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 374] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 375] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 376] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 377] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 378] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 379] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 380] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 381] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 382] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 383] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 384] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 385] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 386] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 387] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 388] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 389] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 390] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 391] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 392] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 393] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 394] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 395] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 396] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 397] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 398] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 399] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 400] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 401] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 402] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 403] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 404] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 405] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 406] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 407] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 408] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 409] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 410] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 411] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 412] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 413] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 414] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 415] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 416] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 417] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 418] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 419] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 420] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 421] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 422] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 423] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 424] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 425] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 426] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 427] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 428] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 429] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 430] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 431] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 432] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 433] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 434] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 435] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 436] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 437] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 438] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 439] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 440] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 441] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 442] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 443] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 444] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 445] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 446] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 447] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 448] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 449] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 450] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 451] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 452] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 453] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 454] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 455] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 456] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 457] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 458] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 459] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 460] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 461] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 462] : loss 0.9089, min_loss 0.9089, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 463] : loss 0.9089, min_loss 0.9089, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 464] : loss 0.9089, min_loss 0.9089, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 465] : loss 0.9088, min_loss 0.9088, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 466] : loss 0.9088, min_loss 0.9088, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 467] : loss 0.9087, min_loss 0.9087, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 468] : loss 0.9087, min_loss 0.9087, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 469] : loss 0.9086, min_loss 0.9086, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 470] : loss 0.9085, min_loss 0.9085, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 471] : loss 0.9085, min_loss 0.9085, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 472] : loss 0.9083, min_loss 0.9083, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 473] : loss 0.9082, min_loss 0.9082, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 474] : loss 0.9081, min_loss 0.9081, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 475] : loss 0.9079, min_loss 0.9079, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 476] : loss 0.9076, min_loss 0.9076, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 477] : loss 0.9074, min_loss 0.9074, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 478] : loss 0.9071, min_loss 0.9071, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 479] : loss 0.9067, min_loss 0.9067, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 480] : loss 0.9063, min_loss 0.9063, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 481] : loss 0.9058, min_loss 0.9058, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 482] : loss 0.9053, min_loss 0.9053, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 483] : loss 0.9047, min_loss 0.9047, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 484] : loss 0.9042, min_loss 0.9042, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 485] : loss 0.9038, min_loss 0.9038, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 486] : loss 0.9035, min_loss 0.9035, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 487] : loss 0.9032, min_loss 0.9032, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 488] : loss 0.9031, min_loss 0.9031, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 489] : loss 0.9030, min_loss 0.9030, train_acc 1.000, test_acc 0.222\n",
      "==> [Epoch 490] : loss 0.9029, min_loss 0.9029, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 491] : loss 0.9029, min_loss 0.9029, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 492] : loss 0.9029, min_loss 0.9029, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 493] : loss 0.9028, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 494] : loss 0.9028, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 495] : loss 0.9028, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 496] : loss 0.9029, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 497] : loss 0.9030, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 498] : loss 0.9030, min_loss 0.9028, train_acc 1.000, test_acc 0.222\n",
      "==> [Epoch 499] : loss 0.9031, min_loss 0.9028, train_acc 1.000, test_acc 0.222\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, test_acc = train(node_list=list(map(lambda x: x[0], N)),\n",
    "                                        edge_list=E,\n",
    "                                        label_list=list(\n",
    "                                            map(lambda x: x[1], N)),\n",
    "                                        T=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1d2e236ffd0>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e236f880>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e235c970>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e234ebb0>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2314340>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2314a90>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e23149d0>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2338100>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2338850>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e232c0a0>],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(train_loss)\n",
    "plt.figure()\n",
    "# 画出train_loss\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(range(epochs), train_loss)\n",
    "plt.xlim((0, epochs))    # 设置x轴的范围\n",
    "plt.ylabel('loss')      # 设置y周标签\n",
    "plt.yticks(np.arange(0, 1.5, 0.2))  # 设置y轴刻度\n",
    "\n",
    "# 画出train_acc\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(range(epochs), train_acc)\n",
    "plt.xlim((0, epochs))\n",
    "plt.ylim((0, 1))\n",
    "plt.ylabel('train_acc')\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "# 画出test_acc\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(range(epochs), test_acc)\n",
    "plt.xlim((0, epochs))\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('test_acc')\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "# 保存图片\n",
    "# plt.savefig(\"./images/result.png\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d6d563c462dbcb2ee090b6970b42fc638e8eb4a4e6decc12c92a9df43cdf15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
