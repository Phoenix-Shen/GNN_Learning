{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import json\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt \n",
    "import torch.nn as nn\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n1', 0), ('n2', 0), ('n3', 0), ('n4', 0), ('n5', 0), ('n6', 0), ('n7', 1), ('n8', 1), ('n9', 1), ('n10', 1), ('n11', 1), ('n12', 1), ('n13', 2), ('n14', 2), ('n15', 2), ('n16', 2), ('n17', 2), ('n18', 2)]\n",
      "[('n1', 'n2'), ('n1', 'n3'), ('n1', 'n5'), ('n2', 'n4'), ('n3', 'n6'), ('n3', 'n9'), ('n4', 'n5'), ('n4', 'n6'), ('n4', 'n8'), ('n5', 'n14'), ('n7', 'n8'), ('n7', 'n9'), ('n7', 'n11'), ('n8', 'n10'), ('n8', 'n11'), ('n8', 'n12'), ('n9', 'n10'), ('n9', 'n14'), ('n10', 'n12'), ('n11', 'n18'), ('n13', 'n15'), ('n13', 'n16'), ('n13', 'n18'), ('n14', 'n16'), ('n14', 'n18'), ('n15', 'n16'), ('n15', 'n18'), ('n17', 'n18')]\n"
     ]
    }
   ],
   "source": [
    "# (node, label)集\n",
    "N = [(\"n{}\".format(i), 0) for i in range(1, 7)] + \\\n",
    "    [(\"n{}\".format(i), 1) for i in range(7, 13)] + \\\n",
    "    [(\"n{}\".format(i), 2) for i in range(13, 19)]\n",
    "# 边集\n",
    "E = [(\"n1\", \"n2\"), (\"n1\", \"n3\"), (\"n1\", \"n5\"),\n",
    "     (\"n2\", \"n4\"),\n",
    "     (\"n3\", \"n6\"), (\"n3\", \"n9\"),\n",
    "     (\"n4\", \"n5\"), (\"n4\", \"n6\"), (\"n4\", \"n8\"),\n",
    "     (\"n5\", \"n14\"),\n",
    "     (\"n7\", \"n8\"), (\"n7\", \"n9\"), (\"n7\", \"n11\"),\n",
    "     (\"n8\", \"n10\"), (\"n8\", \"n11\"), (\"n8\", \"n12\"),\n",
    "     (\"n9\", \"n10\"), (\"n9\", \"n14\"),\n",
    "     (\"n10\", \"n12\"),\n",
    "     (\"n11\", \"n18\"),\n",
    "     (\"n13\", \"n15\"), (\"n13\", \"n16\"), (\"n13\", \"n18\"),\n",
    "     (\"n14\", \"n16\"), (\"n14\", \"n18\"),\n",
    "     (\"n15\", \"n16\"), (\"n15\", \"n18\"),\n",
    "     (\"n17\", \"n18\")]\n",
    "\n",
    "print(N)\n",
    "print(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 显示出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "G=nx.Graph()\n",
    "nodes = list(map(lambda x: x[0], N))\n",
    "G.add_nodes_from(list(map(lambda x:x[0],N)))\n",
    "G.add_edges_from(E)\n",
    "#设置属性\n",
    "ncolor = ['r'] * 6 + ['b'] * 6 + ['g'] * 6\n",
    "nsize = [700] * 6 + [700] * 6 + [700] * 6\n",
    "# 显示Graph\n",
    "plt.figure(1)\n",
    "nx.draw(G, with_labels=True, font_weight='bold',\n",
    "        node_color=ncolor, node_size=nsize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xi(nn.Module):\n",
    "    \"\"\"\n",
    "    实现Xi函数，输入一个batch的相邻节点特征向量对ln，返回的是s*s的A矩阵\n",
    "    \"\"\"\n",
    "    def __init__(self,ln,s) -> None:\n",
    "        super().__init__()\n",
    "        self.ln=ln\n",
    "        self.s = s\n",
    "        # linear layer \n",
    "        self.linear = nn.Linear(2*self.ln,s*s,bias=True)\n",
    "        # activation layer\n",
    "        self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self,X:t.Tensor):\n",
    "        \"\"\"\n",
    "        X: (N,2*ln)输入节点特征以及邻居节点特征concat起来\n",
    "        return : (N,S,S)，输出用于线性变换的参数矩阵\n",
    "        \"\"\"\n",
    "        bs= X.size()[0]\n",
    "        out = self.linear(X)\n",
    "        out = self.tanh(out)\n",
    "        out = out.view(bs,self.s,self.s)\n",
    "        return out\n",
    "    \n",
    "# function Rou\n",
    "class Rou(nn.Module):\n",
    "    def __init__(self,ln,s) -> None:\n",
    "        super().__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(ln,s),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,X:t.Tensor):\n",
    "        out = self.linear(X)\n",
    "        return out\n",
    "\n",
    "class Hw(nn.Module):\n",
    "    def __init__(self,ln,s,mu=0.9) -> None:\n",
    "        super().__init__()\n",
    "        self.ln=ln\n",
    "        self.s=s\n",
    "        self.mu =mu\n",
    "        # init network layers\n",
    "        self.Xi = Xi(self.ln,self.s)\n",
    "        self.Rou = Rou(self.ln,self.s)\n",
    "\n",
    "    def forward(self,X,H,dg_list):\n",
    "        \"\"\"\n",
    "        X (N,2*ln)一个节点特征向量和该节点的某一个邻接向量concatenate得到的向量\n",
    "        H (N,s)对应中心节点的状态向量\n",
    "        dg_list : (N,) 对应中心节点的度的向量\n",
    "        return :(N,s)\n",
    "        \"\"\"\n",
    "        if type(dg_list)==list:\n",
    "            dg_list = t.tensor(dg_list)\n",
    "        elif isinstance(dg_list,t.Tensor):\n",
    "            pass\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"==> dg_list should be list or tensor, not {}\".format(type(dg_list)))\n",
    "        A= (self.Xi(X)*self.mu/self.s)/dg_list.view(-1,1,1)\n",
    "        b=self.Rou(t.chunk(X,chunks=2,dim=1)[0])\n",
    "        # (N, s, s) * (N, s) + (N, s)\n",
    "        out = t.squeeze(t.matmul(A, t.unsqueeze(H, 2)), -1) + b\n",
    "        return out    # (N, s)\n",
    "\n",
    "class AggrSum(nn.Module):\n",
    "    \"\"\"\n",
    "    信息聚合\n",
    "    \"\"\"\n",
    "    def __init__(self,node_num:int) -> None:\n",
    "        super().__init__()\n",
    "        self.V= node_num\n",
    "\n",
    "    def forward(self, H:t.Tensor, X_node: t.Tensor)->t.Tensor:\n",
    "        # H: (N,s)->(V,s)\n",
    "        # X_node:(N,)\n",
    "        mask=t.stack([X_node]*self.V,0)\n",
    "        mask=mask.float()-t.unsqueeze(t.range(0,self.V-1).float(),1)\n",
    "        mask = (mask==0).float()\n",
    "        # (V,N)*(N,s)->(V,s)\n",
    "        return t.mm(mask,H)\n",
    "\n",
    "class OriLinearGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    The graph neural network model\n",
    "    \"\"\"\n",
    "    def __init__(self,node_num,feat_dim,stat_dim,T) -> None:\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        初始化模型函数。\n",
    "        \n",
    "        :param node_num: 节点数量\n",
    "        :param feat_dim: 节点特征维度\n",
    "        :param stat_dim: 节点状态维度\n",
    "        :param T       : GNN更新轮数\n",
    "        \"\"\"\n",
    "        self.node_num=node_num\n",
    "        self.feat_dim= feat_dim\n",
    "        self.stat_dim=stat_dim\n",
    "        self.T=T\n",
    "        # 初始化节点的嵌入向量，也就是hv，(V,ln)\n",
    "        self.node_features=nn.parameter.Parameter(\n",
    "            data=t.randn((self.node_num,self.feat_dim),dtype=t.float32),\n",
    "            requires_grad=True)\n",
    "        # 输出层g\n",
    "        self.linear=nn.Linear(feat_dim+stat_dim,3)\n",
    "        self.softmax = nn.Softmax(0)\n",
    "        # Fw\n",
    "        self.Hw=Hw(feat_dim,stat_dim)\n",
    "        # H的分组求和\n",
    "        self.Aggr = AggrSum(node_num)\n",
    "    \n",
    "    def forward(self,X_Node,X_Neis,dg_list):\n",
    "        \"\"\"前向计算函数。值得注意的是，这里输入的X_Node和N_Neis的第一个维度`N`表示边的个数。\n",
    "        比如：\n",
    "            X_Node: [0, 0, 0, 1, 1, ..., 18, 18]\n",
    "            X_Neis: [1, 2, 4, 1, 4, ..., 11, 13]\n",
    "        :param X_Node: 节点索引\n",
    "        :param X_Neis: X_node对应节点邻居的索引\n",
    "        :param dg_list: 节点的度列表\n",
    "        \"\"\"\n",
    "        node_embeds=self.node_features[X_Node]\n",
    "        neis_embeds=self.node_features[X_Neis]\n",
    "        X=t.cat((node_embeds,neis_embeds),1)\n",
    "        # 初始化节点的状态向量\n",
    "        node_states=t.zeros((self.node_num,self.stat_dim),dtype=t.float32)\n",
    "        # 循环t次\n",
    "        for _ in range(self.T):\n",
    "            # (V,s)->(N,s)\n",
    "            H=t.index_select(node_states,0,X_Node)\n",
    "            #(N,s)->(N,s)\n",
    "            H=self.Hw(X,H,dg_list)\n",
    "            #(N,s)->(V,s)\n",
    "            node_states=self.Aggr(H,X_Node)\n",
    "        out = self.linear(t.cat((self.node_features.data,node_states),1))\n",
    "        out =self.softmax(out)\n",
    "        return out # (V,3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练和评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalclulateAccuracy(output,label):\n",
    "    # output: (N,C)\n",
    "    # label :(N)\n",
    "    output=np.argmax(output,axis=1)\n",
    "    res = output-label\n",
    "    return list(res).count(0)/len(res)\n",
    "\n",
    "# training \n",
    "def train(node_list,edge_list,label_list,T,ndict_path=\"./data/node_dict.json\"):\n",
    "    if os.path.exists(ndict_path):\n",
    "        with open(ndict_path) as fp:\n",
    "            node_dict=json.load(fp)\n",
    "    else:\n",
    "        node_dict=dict([(node,ind) for ind,node in enumerate(node_list)])\n",
    "        node_dict={\"stoi\":node_dict,\n",
    "        \"itos\":node_list}\n",
    "        with open(ndict_path,\"w\") as fp:\n",
    "            json.dump(node_dict,fp)\n",
    "    \n",
    "    # 现在需要生成两个向量\n",
    "    # 第一个向量类似于\n",
    "    #   [0, 0, 0, 1, 1, ..., 18, 18]\n",
    "    # 其中的值表示节点的索引，连续相同索引的个数为该节点的度\n",
    "    # 第二个向量类似于\n",
    "    #   [1, 2, 4, 1, 4, ..., 11, 13]\n",
    "    # 与第一个向量一一对应，表示第一个向量节点的邻居节点\n",
    "\n",
    "    # 得到节点的度 degree\n",
    "    Degree=dict()\n",
    "    for n1,n2 in edge_list:\n",
    "        if n1 in Degree:\n",
    "            Degree[n1].add(n2)\n",
    "        else:\n",
    "            Degree[n1]={n2}\n",
    "        if n2 in Degree:\n",
    "            Degree[n2].add(n1)\n",
    "        else:\n",
    "            Degree[n2]={n1}\n",
    "    \n",
    "    # 生成两个向量\n",
    "    node_inds=[]\n",
    "    node_neis=[]\n",
    "    for n in node_list:\n",
    "        node_inds+=[node_dict[\"stoi\"][n]]*len(Degree[n])\n",
    "        node_neis+=list(map(lambda x:node_dict[\"stoi\"][x],list(Degree[n])))\n",
    "\n",
    "    # 生成度向量\n",
    "    dg_list = list(map(lambda x:len(Degree[node_dict[\"itos\"][x]]),node_inds))\n",
    "\n",
    "    # 训练集和测试集\n",
    "    train_node_list = [0, 1, 2, 6, 7, 8, 12, 13, 14]\n",
    "    train_node_label = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "    test_node_list = [3, 4, 5, 9, 10, 11, 15, 16, 17]\n",
    "    test_node_label = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "\n",
    "    # 开始训练\n",
    "    model = OriLinearGNN(node_num=len(node_list),feat_dim=2,stat_dim=2,T=T)\n",
    "    optimizer=t.optim.Adam(model.parameters(),lr=0.01,weight_decay=0.01)\n",
    "    loss_func  = nn.CrossEntropyLoss(size_average=True)\n",
    "\n",
    "    min_loss=float(\"inf\")\n",
    "    train_loss_list = []\n",
    "    train_acc_list=[]\n",
    "    test_acc_list=[]\n",
    "    node_inds_tensor = t.tensor(node_inds,dtype=t.long)\n",
    "    node_neis_tensor=t.tensor(node_neis,dtype=t.long)\n",
    "    train_label=t.tensor(train_node_label,dtype=t.long)\n",
    "\n",
    "    for ep in range(500):\n",
    "        # 运行模型得到结果\n",
    "        with t.autograd.set_detect_anomaly(True):\n",
    "            res = model(node_inds_tensor, node_neis_tensor, dg_list)  # (V, 3)\n",
    "            train_res = t.index_select(\n",
    "                res, 0, t.Tensor(train_node_list).long())\n",
    "            test_res = t.index_select(\n",
    "                res, 0, t.Tensor(test_node_list).long())\n",
    "            loss = loss_func(input=train_res,\n",
    "                             target=train_label)\n",
    "            loss_val = loss.item()\n",
    "            train_acc = CalclulateAccuracy(\n",
    "                train_res.cpu().detach().numpy(), np.array(train_node_label))\n",
    "            test_acc = CalclulateAccuracy(\n",
    "                test_res.cpu().detach().numpy(), np.array(test_node_label))\n",
    "            # 更新梯度\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "        # 保存loss和acc\n",
    "        train_loss_list.append(loss_val)\n",
    "        test_acc_list.append(test_acc)\n",
    "        train_acc_list.append(train_acc)\n",
    "\n",
    "        if loss_val < min_loss:\n",
    "            min_loss = loss_val\n",
    "        print(\"==> [Epoch {}] : loss {:.4f}, min_loss {:.4f}, train_acc {:.3f}, test_acc {:.3f}\".format(\n",
    "            ep, loss_val, min_loss, train_acc, test_acc))\n",
    "    return train_loss_list, train_acc_list, test_acc_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\develop\\anaconda\\lib\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\22502\\AppData\\Local\\Temp/ipykernel_1952/610473214.py:79: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  mask=mask.float()-t.unsqueeze(t.range(0,self.V-1).float(),1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> [Epoch 0] : loss 1.1045, min_loss 1.1045, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 1] : loss 1.1040, min_loss 1.1040, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 2] : loss 1.1035, min_loss 1.1035, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 3] : loss 1.1030, min_loss 1.1030, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 4] : loss 1.1026, min_loss 1.1026, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 5] : loss 1.1021, min_loss 1.1021, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 6] : loss 1.1017, min_loss 1.1017, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 7] : loss 1.1013, min_loss 1.1013, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 8] : loss 1.1009, min_loss 1.1009, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 9] : loss 1.1005, min_loss 1.1005, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 10] : loss 1.1001, min_loss 1.1001, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 11] : loss 1.0997, min_loss 1.0997, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 12] : loss 1.0992, min_loss 1.0992, train_acc 0.444, test_acc 0.444\n",
      "==> [Epoch 13] : loss 1.0988, min_loss 1.0988, train_acc 0.333, test_acc 0.444\n",
      "==> [Epoch 14] : loss 1.0984, min_loss 1.0984, train_acc 0.333, test_acc 0.444\n",
      "==> [Epoch 15] : loss 1.0979, min_loss 1.0979, train_acc 0.333, test_acc 0.444\n",
      "==> [Epoch 16] : loss 1.0975, min_loss 1.0975, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 17] : loss 1.0969, min_loss 1.0969, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 18] : loss 1.0964, min_loss 1.0964, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 19] : loss 1.0958, min_loss 1.0958, train_acc 0.333, test_acc 0.333\n",
      "==> [Epoch 20] : loss 1.0952, min_loss 1.0952, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 21] : loss 1.0945, min_loss 1.0945, train_acc 0.222, test_acc 0.333\n",
      "==> [Epoch 22] : loss 1.0938, min_loss 1.0938, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 23] : loss 1.0930, min_loss 1.0930, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 24] : loss 1.0922, min_loss 1.0922, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 25] : loss 1.0912, min_loss 1.0912, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 26] : loss 1.0902, min_loss 1.0902, train_acc 0.222, test_acc 0.444\n",
      "==> [Epoch 27] : loss 1.0891, min_loss 1.0891, train_acc 0.444, test_acc 0.444\n",
      "==> [Epoch 28] : loss 1.0879, min_loss 1.0879, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 29] : loss 1.0865, min_loss 1.0865, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 30] : loss 1.0850, min_loss 1.0850, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 31] : loss 1.0834, min_loss 1.0834, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 32] : loss 1.0815, min_loss 1.0815, train_acc 0.444, test_acc 0.222\n",
      "==> [Epoch 33] : loss 1.0794, min_loss 1.0794, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 34] : loss 1.0771, min_loss 1.0771, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 35] : loss 1.0745, min_loss 1.0745, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 36] : loss 1.0715, min_loss 1.0715, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 37] : loss 1.0682, min_loss 1.0682, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 38] : loss 1.0645, min_loss 1.0645, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 39] : loss 1.0605, min_loss 1.0605, train_acc 0.444, test_acc 0.333\n",
      "==> [Epoch 40] : loss 1.0563, min_loss 1.0563, train_acc 0.556, test_acc 0.333\n",
      "==> [Epoch 41] : loss 1.0520, min_loss 1.0520, train_acc 0.556, test_acc 0.333\n",
      "==> [Epoch 42] : loss 1.0477, min_loss 1.0477, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 43] : loss 1.0437, min_loss 1.0437, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 44] : loss 1.0401, min_loss 1.0401, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 45] : loss 1.0371, min_loss 1.0371, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 46] : loss 1.0347, min_loss 1.0347, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 47] : loss 1.0329, min_loss 1.0329, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 48] : loss 1.0316, min_loss 1.0316, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 49] : loss 1.0307, min_loss 1.0307, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 50] : loss 1.0300, min_loss 1.0300, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 51] : loss 1.0295, min_loss 1.0295, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 52] : loss 1.0291, min_loss 1.0291, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 53] : loss 1.0288, min_loss 1.0288, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 54] : loss 1.0285, min_loss 1.0285, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 55] : loss 1.0283, min_loss 1.0283, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 56] : loss 1.0280, min_loss 1.0280, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 57] : loss 1.0279, min_loss 1.0279, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 58] : loss 1.0277, min_loss 1.0277, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 59] : loss 1.0275, min_loss 1.0275, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 60] : loss 1.0274, min_loss 1.0274, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 61] : loss 1.0272, min_loss 1.0272, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 62] : loss 1.0271, min_loss 1.0271, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 63] : loss 1.0269, min_loss 1.0269, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 64] : loss 1.0268, min_loss 1.0268, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 65] : loss 1.0267, min_loss 1.0267, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 66] : loss 1.0265, min_loss 1.0265, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 67] : loss 1.0264, min_loss 1.0264, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 68] : loss 1.0263, min_loss 1.0263, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 69] : loss 1.0261, min_loss 1.0261, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 70] : loss 1.0260, min_loss 1.0260, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 71] : loss 1.0258, min_loss 1.0258, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 72] : loss 1.0256, min_loss 1.0256, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 73] : loss 1.0254, min_loss 1.0254, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 74] : loss 1.0252, min_loss 1.0252, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 75] : loss 1.0250, min_loss 1.0250, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 76] : loss 1.0247, min_loss 1.0247, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 77] : loss 1.0244, min_loss 1.0244, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 78] : loss 1.0241, min_loss 1.0241, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 79] : loss 1.0237, min_loss 1.0237, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 80] : loss 1.0234, min_loss 1.0234, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 81] : loss 1.0230, min_loss 1.0230, train_acc 0.667, test_acc 0.556\n",
      "==> [Epoch 82] : loss 1.0226, min_loss 1.0226, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 83] : loss 1.0223, min_loss 1.0223, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 84] : loss 1.0220, min_loss 1.0220, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 85] : loss 1.0217, min_loss 1.0217, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 86] : loss 1.0214, min_loss 1.0214, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 87] : loss 1.0211, min_loss 1.0211, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 88] : loss 1.0209, min_loss 1.0209, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 89] : loss 1.0206, min_loss 1.0206, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 90] : loss 1.0203, min_loss 1.0203, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 91] : loss 1.0201, min_loss 1.0201, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 92] : loss 1.0198, min_loss 1.0198, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 93] : loss 1.0196, min_loss 1.0196, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 94] : loss 1.0194, min_loss 1.0194, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 95] : loss 1.0191, min_loss 1.0191, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 96] : loss 1.0189, min_loss 1.0189, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 97] : loss 1.0186, min_loss 1.0186, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 98] : loss 1.0184, min_loss 1.0184, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 99] : loss 1.0181, min_loss 1.0181, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 100] : loss 1.0178, min_loss 1.0178, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 101] : loss 1.0174, min_loss 1.0174, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 102] : loss 1.0170, min_loss 1.0170, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 103] : loss 1.0165, min_loss 1.0165, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 104] : loss 1.0159, min_loss 1.0159, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 105] : loss 1.0153, min_loss 1.0153, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 106] : loss 1.0147, min_loss 1.0147, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 107] : loss 1.0139, min_loss 1.0139, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 108] : loss 1.0131, min_loss 1.0131, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 109] : loss 1.0122, min_loss 1.0122, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 110] : loss 1.0111, min_loss 1.0111, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 111] : loss 1.0099, min_loss 1.0099, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 112] : loss 1.0086, min_loss 1.0086, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 113] : loss 1.0070, min_loss 1.0070, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 114] : loss 1.0052, min_loss 1.0052, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 115] : loss 1.0031, min_loss 1.0031, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 116] : loss 1.0008, min_loss 1.0008, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 117] : loss 0.9981, min_loss 0.9981, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 118] : loss 0.9952, min_loss 0.9952, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 119] : loss 0.9920, min_loss 0.9920, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 120] : loss 0.9887, min_loss 0.9887, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 121] : loss 0.9854, min_loss 0.9854, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 122] : loss 0.9823, min_loss 0.9823, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 123] : loss 0.9794, min_loss 0.9794, train_acc 0.667, test_acc 0.444\n",
      "==> [Epoch 124] : loss 0.9770, min_loss 0.9770, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 125] : loss 0.9750, min_loss 0.9750, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 126] : loss 0.9735, min_loss 0.9735, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 127] : loss 0.9724, min_loss 0.9724, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 128] : loss 0.9715, min_loss 0.9715, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 129] : loss 0.9709, min_loss 0.9709, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 130] : loss 0.9705, min_loss 0.9705, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 131] : loss 0.9701, min_loss 0.9701, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 132] : loss 0.9699, min_loss 0.9699, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 133] : loss 0.9697, min_loss 0.9697, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 134] : loss 0.9695, min_loss 0.9695, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 135] : loss 0.9694, min_loss 0.9694, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 136] : loss 0.9693, min_loss 0.9693, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 137] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 138] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 139] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 140] : loss 0.9692, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 141] : loss 0.9693, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 142] : loss 0.9693, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 143] : loss 0.9694, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 144] : loss 0.9695, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 145] : loss 0.9697, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 146] : loss 0.9698, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 147] : loss 0.9700, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 148] : loss 0.9701, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 149] : loss 0.9702, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 150] : loss 0.9702, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 151] : loss 0.9702, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 152] : loss 0.9701, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 153] : loss 0.9699, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 154] : loss 0.9697, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 155] : loss 0.9694, min_loss 0.9692, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 156] : loss 0.9690, min_loss 0.9690, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 157] : loss 0.9686, min_loss 0.9686, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 158] : loss 0.9681, min_loss 0.9681, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 159] : loss 0.9676, min_loss 0.9676, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 160] : loss 0.9671, min_loss 0.9671, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 161] : loss 0.9666, min_loss 0.9666, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 162] : loss 0.9661, min_loss 0.9661, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 163] : loss 0.9655, min_loss 0.9655, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 164] : loss 0.9649, min_loss 0.9649, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 165] : loss 0.9643, min_loss 0.9643, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 166] : loss 0.9637, min_loss 0.9637, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 167] : loss 0.9631, min_loss 0.9631, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 168] : loss 0.9625, min_loss 0.9625, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 169] : loss 0.9618, min_loss 0.9618, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 170] : loss 0.9610, min_loss 0.9610, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 171] : loss 0.9602, min_loss 0.9602, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 172] : loss 0.9594, min_loss 0.9594, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 173] : loss 0.9584, min_loss 0.9584, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 174] : loss 0.9574, min_loss 0.9574, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 175] : loss 0.9562, min_loss 0.9562, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 176] : loss 0.9548, min_loss 0.9548, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 177] : loss 0.9532, min_loss 0.9532, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 178] : loss 0.9514, min_loss 0.9514, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 179] : loss 0.9493, min_loss 0.9493, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 180] : loss 0.9470, min_loss 0.9470, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 181] : loss 0.9444, min_loss 0.9444, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 182] : loss 0.9416, min_loss 0.9416, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 183] : loss 0.9387, min_loss 0.9387, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 184] : loss 0.9357, min_loss 0.9357, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 185] : loss 0.9327, min_loss 0.9327, train_acc 0.667, test_acc 0.333\n",
      "==> [Epoch 186] : loss 0.9298, min_loss 0.9298, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 187] : loss 0.9272, min_loss 0.9272, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 188] : loss 0.9247, min_loss 0.9247, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 189] : loss 0.9225, min_loss 0.9225, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 190] : loss 0.9206, min_loss 0.9206, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 191] : loss 0.9190, min_loss 0.9190, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 192] : loss 0.9176, min_loss 0.9176, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 193] : loss 0.9165, min_loss 0.9165, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 194] : loss 0.9156, min_loss 0.9156, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 195] : loss 0.9149, min_loss 0.9149, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 196] : loss 0.9144, min_loss 0.9144, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 197] : loss 0.9140, min_loss 0.9140, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 198] : loss 0.9137, min_loss 0.9137, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 199] : loss 0.9135, min_loss 0.9135, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 200] : loss 0.9134, min_loss 0.9134, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 201] : loss 0.9133, min_loss 0.9133, train_acc 0.778, test_acc 0.444\n",
      "==> [Epoch 202] : loss 0.9133, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 203] : loss 0.9134, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 204] : loss 0.9135, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 205] : loss 0.9136, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 206] : loss 0.9138, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 207] : loss 0.9140, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 208] : loss 0.9142, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 209] : loss 0.9143, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 210] : loss 0.9144, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 211] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 212] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 213] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 214] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 215] : loss 0.9146, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 216] : loss 0.9145, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 217] : loss 0.9144, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 218] : loss 0.9142, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 219] : loss 0.9140, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 220] : loss 0.9138, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 221] : loss 0.9136, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 222] : loss 0.9134, min_loss 0.9133, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 223] : loss 0.9131, min_loss 0.9131, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 224] : loss 0.9128, min_loss 0.9128, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 225] : loss 0.9126, min_loss 0.9126, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 226] : loss 0.9123, min_loss 0.9123, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 227] : loss 0.9120, min_loss 0.9120, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 228] : loss 0.9117, min_loss 0.9117, train_acc 0.778, test_acc 0.333\n",
      "==> [Epoch 229] : loss 0.9115, min_loss 0.9115, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 230] : loss 0.9112, min_loss 0.9112, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 231] : loss 0.9110, min_loss 0.9110, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 232] : loss 0.9107, min_loss 0.9107, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 233] : loss 0.9105, min_loss 0.9105, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 234] : loss 0.9104, min_loss 0.9104, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 235] : loss 0.9102, min_loss 0.9102, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 236] : loss 0.9101, min_loss 0.9101, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 237] : loss 0.9100, min_loss 0.9100, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 238] : loss 0.9099, min_loss 0.9099, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 239] : loss 0.9098, min_loss 0.9098, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 240] : loss 0.9098, min_loss 0.9098, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 241] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 242] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 243] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 244] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 245] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 246] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.222\n",
      "==> [Epoch 247] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 248] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 249] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 250] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 251] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 252] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 253] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 254] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 255] : loss 0.9098, min_loss 0.9097, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 256] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 257] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 258] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 259] : loss 0.9097, min_loss 0.9097, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 260] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 261] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 262] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 263] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 264] : loss 0.9096, min_loss 0.9096, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 265] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 266] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 267] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 268] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 269] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 270] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 271] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 272] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 273] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 274] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 275] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 276] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 277] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 278] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 279] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 280] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 281] : loss 0.9095, min_loss 0.9095, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 282] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 283] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 284] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 285] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 286] : loss 0.9094, min_loss 0.9094, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 287] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 288] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 289] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 290] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 291] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 292] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 293] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 294] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 295] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 296] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 297] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 298] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 299] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 300] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 301] : loss 0.9093, min_loss 0.9093, train_acc 1.000, test_acc 0.444\n",
      "==> [Epoch 302] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 303] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 304] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 305] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 306] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 307] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 308] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 309] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 310] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 311] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 312] : loss 0.9093, min_loss 0.9093, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 313] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 314] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 315] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 316] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 317] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.444\n",
      "==> [Epoch 318] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 319] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 320] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 321] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 322] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 323] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 324] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 325] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 326] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 327] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 328] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 329] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 330] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 331] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 332] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 333] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 334] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 335] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 336] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 337] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 338] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 339] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 340] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 341] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 342] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 343] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 344] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 345] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 346] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 347] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 348] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 349] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 350] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 351] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 352] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 353] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 354] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 355] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 356] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 357] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 358] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 359] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 360] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 361] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 362] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 363] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 364] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 365] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 366] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 367] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 368] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 369] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 370] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 371] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 372] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 373] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 374] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 375] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 376] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 377] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 378] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 379] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 380] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 381] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 382] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 383] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 384] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 385] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 386] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 387] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 388] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 389] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 390] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 391] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 392] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 393] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 394] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 395] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 396] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 397] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 398] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 399] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 400] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 401] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 402] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 403] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 404] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 405] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 406] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 407] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 408] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 409] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 410] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 411] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 412] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 413] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 414] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 415] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 416] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 417] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 418] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 419] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 420] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 421] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 422] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 423] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 424] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 425] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 426] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 427] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 428] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 429] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 430] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 431] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 432] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 433] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 434] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 435] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 436] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 437] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 438] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 439] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 440] : loss 0.9092, min_loss 0.9092, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 441] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 442] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 443] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 444] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 445] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 446] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 447] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 448] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 449] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 450] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 451] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 452] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 453] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 454] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 455] : loss 0.9091, min_loss 0.9091, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 456] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 457] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 458] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 459] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 460] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 461] : loss 0.9090, min_loss 0.9090, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 462] : loss 0.9089, min_loss 0.9089, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 463] : loss 0.9089, min_loss 0.9089, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 464] : loss 0.9089, min_loss 0.9089, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 465] : loss 0.9088, min_loss 0.9088, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 466] : loss 0.9088, min_loss 0.9088, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 467] : loss 0.9087, min_loss 0.9087, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 468] : loss 0.9087, min_loss 0.9087, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 469] : loss 0.9086, min_loss 0.9086, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 470] : loss 0.9085, min_loss 0.9085, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 471] : loss 0.9085, min_loss 0.9085, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 472] : loss 0.9083, min_loss 0.9083, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 473] : loss 0.9082, min_loss 0.9082, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 474] : loss 0.9081, min_loss 0.9081, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 475] : loss 0.9079, min_loss 0.9079, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 476] : loss 0.9076, min_loss 0.9076, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 477] : loss 0.9074, min_loss 0.9074, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 478] : loss 0.9071, min_loss 0.9071, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 479] : loss 0.9067, min_loss 0.9067, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 480] : loss 0.9063, min_loss 0.9063, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 481] : loss 0.9058, min_loss 0.9058, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 482] : loss 0.9053, min_loss 0.9053, train_acc 0.889, test_acc 0.333\n",
      "==> [Epoch 483] : loss 0.9047, min_loss 0.9047, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 484] : loss 0.9042, min_loss 0.9042, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 485] : loss 0.9038, min_loss 0.9038, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 486] : loss 0.9035, min_loss 0.9035, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 487] : loss 0.9032, min_loss 0.9032, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 488] : loss 0.9031, min_loss 0.9031, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 489] : loss 0.9030, min_loss 0.9030, train_acc 1.000, test_acc 0.222\n",
      "==> [Epoch 490] : loss 0.9029, min_loss 0.9029, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 491] : loss 0.9029, min_loss 0.9029, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 492] : loss 0.9029, min_loss 0.9029, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 493] : loss 0.9028, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 494] : loss 0.9028, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 495] : loss 0.9028, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 496] : loss 0.9029, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 497] : loss 0.9030, min_loss 0.9028, train_acc 1.000, test_acc 0.333\n",
      "==> [Epoch 498] : loss 0.9030, min_loss 0.9028, train_acc 1.000, test_acc 0.222\n",
      "==> [Epoch 499] : loss 0.9031, min_loss 0.9028, train_acc 1.000, test_acc 0.222\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc, test_acc = train(node_list=list(map(lambda x: x[0], N)),\n",
    "                                        edge_list=E,\n",
    "                                        label_list=list(\n",
    "                                            map(lambda x: x[1], N)),\n",
    "                                        T=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.YTick at 0x1d2e236ffd0>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e236f880>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e235c970>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e234ebb0>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2314340>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2314a90>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e23149d0>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2338100>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e2338850>,\n",
       "  <matplotlib.axis.YTick at 0x1d2e232c0a0>],\n",
       " [Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, ''),\n",
       "  Text(0, 0, '')])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = len(train_loss)\n",
    "plt.figure()\n",
    "# 画出train_loss\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(range(epochs), train_loss)\n",
    "plt.xlim((0, epochs))    # 设置x轴的范围\n",
    "plt.ylabel('loss')      # 设置y周标签\n",
    "plt.yticks(np.arange(0, 1.5, 0.2))  # 设置y轴刻度\n",
    "\n",
    "# 画出train_acc\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(range(epochs), train_acc)\n",
    "plt.xlim((0, epochs))\n",
    "plt.ylim((0, 1))\n",
    "plt.ylabel('train_acc')\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "# 画出test_acc\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(range(epochs), test_acc)\n",
    "plt.xlim((0, epochs))\n",
    "plt.ylim((0, 1))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('test_acc')\n",
    "plt.yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "# 保存图片\n",
    "# plt.savefig(\"./images/result.png\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d6d563c462dbcb2ee090b6970b42fc638e8eb4a4e6decc12c92a9df43cdf15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
