{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch_geometric.data.Data\n",
    "[documents](https://pytorch-geometric.readthedocs.io/en/latest/notes/introduction.html#data-handling-of-graphs)\n",
    "### data.x 顶点的特征矩阵 dim:[num_nodes,num_node_features]\n",
    "### data.edge_index 图的连通性矩阵 dim:[2,num_edges] torch.long\n",
    "### data.edge_attr 边的特征矩阵 dim:[num_edges,num_edge_features]\n",
    "### data.y 要训练的目标，dim随意，例如边的target是[num_nodes,*],全局的是[1,*]\n",
    "### data.pos 节点的位置矩阵 dim[num_nodes,num_dimensions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[3, 1], edge_index=[2, 4])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#定义一个无权重的无向图，它有3个顶点4条便，每个顶点有一个特征\n",
    "\n",
    "import torch as t\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = t.tensor([[0,1,1,2],[1,0,2,1]],dtype=t.long)\n",
    "x= t.tensor([[-1],[0],[1]],dtype=t.float32)\n",
    "\n",
    "data=Data(x=x,edge_index=edge_index)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edge_index是定义从一个边的起始点和终点，而不是节点下标的元组，如果要这么写的话，调用transpose和contiguous就可以\n",
    "\n",
    "contiguous() → Tensor\n",
    "        返回一个内存连续的有相同数据的 tensor，如果原 tensor 内存连续则返回原 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "edge_index2 = t.tensor([[0, 1],\n",
    "                           [1, 0],\n",
    "                           [1, 2],\n",
    "                           [2, 1]], dtype=t.long)\n",
    "edge_index2.t()\n",
    "print(edge_index2.t().contiguous())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**虽然一个图只有两个边，我们要定义4个下标对来表示边的两个方向**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edge_index', 'x']\n",
      "tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "x found in data , it is tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edge_index found in data , it is tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 访问data的属性\n",
    "\n",
    "print(data.keys)\n",
    "print(data[\"x\"])\n",
    "\n",
    "for key,item in data:\n",
    "    print(f'{key} found in data , it is {item}')\n",
    "\n",
    "print(\"edge_attr\" in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "1\n",
      "4\n",
      "0\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(data.num_nodes)\n",
    "print(data.num_node_features)\n",
    "print(data.num_edges)\n",
    "print(data.num_edge_features)\n",
    "print(data.has_isolated_nodes())\n",
    "print(data.has_self_loops())\n",
    "print(data.is_directed())\n",
    "print(data.is_undirected())\n",
    "print(data.is_cuda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Datasets\n",
    "Planetoid 数据集 图分类数据集及其清洁版本，QM7 QM9数据集 少数3d网格、电云数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENZYMES(600)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root=\"./datasets/ENZYMES\",name=\"ENZYMES\")\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "6\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we now have access to all 600 graphs in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 168], x=[37, 3], y=[1])\n",
      "True\n",
      "tensor([5])\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "print(data)\n",
    "print(data.is_undirected())\n",
    "print(data.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一张图含有37个节点，一个节点有3个特征，有168/2 = 84 条边，然后这张图有一个类别，此外，data对象包含有一个图级别的target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用切片 long或者bool张量来分割数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENZYMES(540) ENZYMES(60)\n"
     ]
    }
   ],
   "source": [
    "train_data = dataset[:540]\n",
    "test_data = dataset[540:]\n",
    "print(train_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nEQUALS to : \\npermutation = t.randperm(len(dataset))\\ndataset = dataset [perm]\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle\n",
    "dataset = dataset.shuffle()\n",
    "\"\"\" \n",
    "EQUALS to : \n",
    "permutation = t.randperm(len(dataset))\n",
    "dataset = dataset [perm]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORA\n",
    "半监督学习的标准数据集，用于节点分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cora()\n",
      "1\n",
      "7\n",
      "1433\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root=\"./datasets/Cora\",name=\"Cora\")\n",
    "print(dataset)\n",
    "print(len(dataset))\n",
    "print(dataset.num_classes)\n",
    "print(dataset.num_node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "140\n",
      "torch.Size([2708])\n",
      "tensor([ True,  True,  True,  ..., False, False, False])\n",
      "500\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(data.is_undirected())\n",
    "print(data.train_mask.sum().item())\n",
    "print(data.train_mask.shape)\n",
    "print(data.train_mask)\n",
    "print(data.val_mask.sum().item())\n",
    "print(data.test_mask.sum().item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这次，data对象中存储着每个节点的标签，和额外的顶点级别的属性：train_mask,val_mask,test_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mini - batches\n",
    "神经网络经常使用batch来加快速度，PYG也有类似功能，PyG通过创建稀疏的块状对角线邻接矩阵来实现小批量的并行化。这种组合允许在一个批次中对实例进行不同数量的节点和边的训练\n",
    "\n",
    "pyg有自己的dataloader： torch_geometric.loader.DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 3120], x=[839, 21], y=[32], batch=[839], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3968], x=[1022, 21], y=[32], batch=[1022], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4190], x=[1081, 21], y=[32], batch=[1081], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3948], x=[994, 21], y=[32], batch=[994], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4632], x=[1344, 21], y=[32], batch=[1344], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4002], x=[1083, 21], y=[32], batch=[1083], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4162], x=[1049, 21], y=[32], batch=[1049], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3832], x=[1000, 21], y=[32], batch=[1000], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3874], x=[996, 21], y=[32], batch=[996], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3884], x=[1053, 21], y=[32], batch=[1053], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4536], x=[1146, 21], y=[32], batch=[1146], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3924], x=[1130, 21], y=[32], batch=[1130], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3830], x=[998, 21], y=[32], batch=[998], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4262], x=[1072, 21], y=[32], batch=[1072], ptr=[33])\n",
      "DataBatch(edge_index=[2, 4040], x=[1057, 21], y=[32], batch=[1057], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3896], x=[974, 21], y=[32], batch=[974], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3856], x=[1058, 21], y=[32], batch=[1058], ptr=[33])\n",
      "DataBatch(edge_index=[2, 3796], x=[961, 21], y=[32], batch=[961], ptr=[33])\n",
      "DataBatch(edge_index=[2, 2812], x=[723, 21], y=[24], batch=[723], ptr=[25])\n",
      "-------------------\n",
      "Data(edge_index=[2, 92], x=[25, 21], y=[1])\n",
      "batch.num_graphs is 24\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "dataset = TUDataset(root=\"./datasets/ENZYMES\",name = \"ENZYMES\",use_node_attr=True)\n",
    "loader=DataLoader(dataset,batch_size=32,shuffle=True)\n",
    "for batch in loader : \n",
    "    print(batch)\n",
    "print(\"-------------------\")\n",
    "print(dataset[2])\n",
    "print(f\"batch.num_graphs is {batch.num_graphs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中tg.data.Batch 是从 tg.data.Data继承过来的，它包含了batch中所有的信息\n",
    "\n",
    "batch是一个向量，它保存了节点到节点属于的图的映射"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "         1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
       "         2,  2,  2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "         3,  3,  3,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
       "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
       "         5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
       "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
       "         8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
       "         9,  9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11,\n",
       "        11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
       "        13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
       "        14, 14, 14, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15,\n",
       "        15, 15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
       "        16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
       "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
       "        19, 19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
       "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21,\n",
       "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "        21, 21, 21, 21, 21, 21, 21, 21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22,\n",
       "        22, 22, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
       "        23, 23, 23])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以对它们进行处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(edge_index=[2, 3752], x=[1008, 21], y=[32], batch=[1008], ptr=[33])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 21])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = TUDataset(root=\"./datasets/ENZYMES\",\n",
    "                    name=\"ENZYMES\", use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "for batch_data in loader:\n",
    "    print(batch_data)\n",
    "    break\n",
    "\n",
    "batch_data.num_graphs\n",
    "\n",
    "from torch_scatter import scatter_mean\n",
    "x = scatter_mean(batch_data.x, batch_data.batch, dim=0)\n",
    "x.size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA TRANSFORMS\n",
    "转化是torchvision里面一个很常见的操作，它被用于处理图片\n",
    "\n",
    "可以向torchvision里面一样，将它们变成一个流水线\n",
    "```python\n",
    "import torch_geometric.transforms.Compose\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://shapenet.cs.stanford.edu/media/shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Extracting datasets\\ShapeNet\\shapenetcore_partanno_segmentation_benchmark_v0_normal.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[2518, 3], y=[2518], pos=[2518, 3], category=[1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.datasets import ShapeNet\n",
    "dataset = ShapeNet(root=\"./datasets/ShapeNet\",categories=[\"Airplane\"])\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "dataset = ShapeNet( root=\"./datasets/ShapeNet\",\n",
    "                    categories=[\"Airplane\"],\n",
    "                    pre_transform=T.KNNGraph(k=6),\n",
    ")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用pre_transform去处理数据，再将它存到磁盘上去，下次这个数据集被载入的时候就不需要做预处理，如果pre_transform没有与之匹配的数据集，将会得到警告"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用GNN处理数据\n",
    "学习了 dataset dataloader之后，来进行一个实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "dataset = Planetoid(root=\"./datasets/Cora\",name=\"Cora\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(t.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1=GCNConv(dataset.num_node_features,16)\n",
    "        self.conv2=GCNConv(16,dataset.num_classes)\n",
    "    \n",
    "    def forward(self,data):\n",
    "        x,edge_index=data.x,data.edge_index\n",
    "        x=self.conv1(x,edge_index)\n",
    "        x=F.relu(x)\n",
    "        x=F.dropout(x,training=self.training)\n",
    "        x=self.conv2(x,edge_index)\n",
    "        return F.log_softmax(x,dim=1)\n",
    "\n",
    "device=t.device(\"cuda\" if t.cuda.is_available() else \"cpu\")\n",
    "model=GCN().to(device=device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = t.optim.Adam(model.parameters(),lr=0.01,weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out=model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask],data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7990\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dim=1)\n",
    "correct = (pred[data.test_mask] == data.y[data.test_mask]).sum()\n",
    "acc = int(correct) / int(data.test_mask.sum())\n",
    "print(f'Accuracy: {acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXERCISES\n",
    "1. What does edge_index.t().contiguous() do?\n",
    "\n",
    "首先转置一下，然后调用contiguous进行深拷贝，保证数据是连续的，而不仅仅是改变数组的映射，在这里我觉得是出于性能考虑\n",
    "\n",
    "2. Load the \"IMDB-BINARY\" dataset from the TUDataset benchmark suite and randomly split it into 80%/10%/10% training, validation and test graphs.\n",
    "\n",
    "使用上面单元格里的切片就可以做到\n",
    "```python\n",
    "train_data = dataset[:540]\n",
    "test_data = dataset[540:]\n",
    "print(train_data,test_data)\n",
    "```\n",
    "\n",
    "3. What does each number of the following output mean?\n",
    "```python\n",
    "print(batch)\n",
    ">>> DataBatch(batch=[1082], edge_index=[2, 4066], x=[1082, 21], y=[32])\n",
    "```\n",
    "\n",
    "batch=1082 : 有1082个节点\n",
    "edge_index=[2,4066]:一共有4066条边\n",
    "x=[1082,21]:有1082个节点，每个节点有21个features\n",
    "y=[32] batch有32个标签，这里特征是全局的，也就是一个图一个标签\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d6d563c462dbcb2ee090b6970b42fc638e8eb4a4e6decc12c92a9df43cdf15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
