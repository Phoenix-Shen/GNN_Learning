# Graph Neural Network

## 1.图

### 1.1 什么是图

在数学中，图是描述于一组对象的结构，其中某些对象对在某种意义上是“相关的”。这些对象对应于称为顶点的数学抽象（也称为节点或点），并且每个相关的顶点对都称为边（也称为链接或线）。通常，图形以图解形式描绘为顶点的一组点或环，并通过边的线或曲线连接。 图形是离散数学的研究对象之一。

图分为有向图和无向图两类

### 1.2 图的表示

图 G 是一个有序二元组(V,E)，其中 V 称为顶集(Vertices Set)，E 称为边集(Edges set)，E 与 V 不相交。它们亦可写成 V(G)和 E(G)。其中，顶集的元素被称为顶点(Vertex)，边集的元素被称为边(edge)。

在存储上，可以使用数组（邻接矩阵）、邻接表、十字链表、邻接多重表等等表示。

### 1.3 相关概念

|                 概念                  | 解释                                                                                                   |
| :-----------------------------------: | ------------------------------------------------------------------------------------------------------ |
|               阶 order                | 顶点的个数                                                                                             |
|             子图 subgraph             | G'=(V',E') 其中 V'、E'分别是 V、E 的子集                                                               |
|               度 degree               | 无向图中节点 v 边的数量称为 v 的度                                                                     |
|       出度、入度 in\out degree        | 有向图中以 v 为起点和以 v 为终点的边的数量分别称为 v 的出度和入度                                      |
|                连通图                 | 无向图中任意节点 i 能够通过边到达节点 j，称为连通图                                                    |
|               连通分量                | 无向图 G 的一个极大连通子图称为 G 的一个连通分量，连通图只有一个连通分量，非连通的无向图有多个连通分量 |
|               强连通图                | 给定有向图 G=（V，E），任意两个节点 uv 都能够相互可达，G 是强连通图                                    |
|               弱连通图                | 如果有向图 G 去掉边的方向后满足无向图的连通标准，那么 G 是弱连通图                                     |
|               最短路径                | 顶点 u 到 v 所经过的最少边的数量称为最短路径                                                           |
|                图直径                 | 对于所有的顶点 uv，图直径是它们最短路径的最大值                                                        |
|               度中心性                | 度中心性=degree(v)/(n-1)其中 n 是顶点的数量                                                            |
| 特征向量中心性 eigenvector centrality | 一个节点的中心性是相邻节点中心性的函数，这是它的基本思想                                               |
|   中介中心性 betweenness centrality   | = 经过该节点的最短路径数/其余两两节点的最短路径数量                                                    |

|连接中心性 closeness|= (n-1)/节点到其它节点最短路径之和

## 2. GNN

### 2.1 GNN 的起源

两种动机：一种来自于 CNN，一种来源于图嵌入，所谓嵌⼊，就是对图的节点、边或者⼦图(subgraph)学习得到⼀个低维的向 量表⽰，传统的机器学习⽅法通常基于⼈⼯特征⼯程来构建特征，但是这种⽅法受限于灵活性不⾜、表达能⼒不⾜以及⼯程量过⼤的问题

### 2.2 与传统 NN 的区别

CNN 和 RNN 不能够适当的处理图结构的输入，GNN 采⽤在每个节点上分别传播(propagate)的⽅式进⾏学习，由此忽略了 节点的顺序，相当于 GNN 的输出会随着输⼊的不同⽽不同。

### 2.3 分类

- 图卷积网络和图注意力网络，因为涉及到传播步骤。
- 图的空域网络，常用于动态图
- 图的自编码，该模型通常使用无监督学习的方式
- 图生成网络，因为是生成式网络
